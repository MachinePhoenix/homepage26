<!DOCTYPE html>
<html>

  <head>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-RFR2GFKT75"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-RFR2GFKT75');
  </script> -->
  <!-- Google Tag Manager -->
  <!-- <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  })(window,document,'script','dataLayer','GTM-NC38VTD');</script> -->
  <!-- End Google Tag Manager -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <!-- <meta http-equiv="refresh" content="0; URL=https://cs.stanford.edu/~leoyuan/"> -->

  <meta name="viewport" content="width=device-width, initial-scale=1">
	  
	<!-- <meta name="google-site-verification" content="u_--0s_Uw50r4zCgRrzltkmFhNCduYOJwPGlKVTuNJU" /> -->

  <title>Yue Xin</title>
  <meta name="description" lang="en" content="This is an academic website for me">
  <meta name="keywords" lang="en" content="Yue Xin" />
  

  <link rel="shortcut icon" href="images/me.jpg">
  <link rel="stylesheet" href="main.css">
  <link rel="stylesheet" href="css/custom.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="css/academicons.css"/>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">


  <script src="js/jquery-2.1.3.min.js"> </script>

  <!--[if lt IE 9]>
<script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/r29/html5.min.js">
</script>
<![endif]-->

  <script type="text/javascript">
    function ShowHide(divId, linkDivId) {
        if(document.getElementById(divId).style.display == 'none') {
            document.getElementById(divId).style.display='block';
            document.getElementById(linkDivId).style.display='none'; // Hide the "read more" link
        }
        else {
            document.getElementById(divId).style.display = 'none';
        }
    }
  </script>

  <style>
    /* 为所有列表项设置样式 */
    li.indented {
        position: relative;
        padding-left: 90px; /* 这是对齐效果的关键，可以根据实际内容调整这个值 */
    }

    li.indented::before {
        content: attr(data-date);
        position: absolute;
        left: 0;
        top: 0;
        white-space: nowrap;
    }
  </style>
  

  
</head>


<body>

    <!-- Google Tag Manager (noscript) -->
<!-- <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NC38VTD"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> -->
<!-- End Google Tag Manager (noscript) -->

    <header class="site-header">

  <div class="wrapper">
<nav class="site-nav">
  <a href="#" class="menu-icon">
    <svg viewBox="0 0 18 15">
      <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
      <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
      <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
    </svg>
  </a>

  <div class="trigger">
    <a class="page-link" href="#bio"><b>Biography</b></a>
	  <a class="page-link" href="#publications"><b>Publications</b></a>
    <a class="page-link" href="#timeline"><b>Research Experience</b></a>
    <a class="page-link" href="#timeline2"><b>Engineering Experience</b></a>
	  <a class="page-link" href="#competitions"><b>Competitions</b></a>
    <a class="page-link" href="#awards"><b>Honors & Awards</b></a>
    <!--<a class="page-link" href="#otherprojects">Projects</a>-->
    <!-- Button for Posts -->
  </div>
</nav>
  </div>
</header>

  <div id="profile-cover" class="cover shallow-bg img-responsive"> 
    <div id="profile-namecard" class="profile-wrapper wrapper-light">
      <div id="my-pic" class="profile-col profile-col-1">
        <img id="profile-avatar" src="images/me.jpg" alt="Me" class="circle-img border-dark"-/>
      </div>
      <div id="my-contact" class="profile-col profile-col-2">
        <div id="my-name" class="text-grey-dark">
          Yue Xin<br>
        </div>
        <div id="my-title" class="text-grey">
          Shanghai Jiao Tong University
        </div>
        <div id="my-email" class="text-grey-light">
          xinyuexiong@sjtu.edu.cn
        </div>

	</div>
        <div class="social-media">
          <a href="https://scholar.google.com/citations?user=AAMp54AAAAAJ&hl=zh-CN" target="_blank" class="icon-button linkedin">
          <i class="ai ai-google-scholar-square icon-linkedin"></i>
            <span></span>
          </a>

          <a href="https://github.com/MachinePhoenix" target="_blank" class="icon-button github">
            <i class="fa fa-github icon-github"></i>
            <span></span>
          </a>

          <!-- <a href="https://www.linkedin.com/in/jun-cen-45b995219/" target="_blank" class="icon-button linkedin">
            <i class="fa fa-linkedin icon-linkedin"></i>
            <span></span>
          </a> -->
         
          <a href="data/Academic_CV_en.pdf" target="_blank" class="icon-button github">
            <i class="ai ai-cv icon-github"></i>
            <span></span>
          </a>

          <a href="xinyuexiong@sjtu.edu.cn" target="_blank" class="icon-button linkedin">
            <i class="fa fa-envelope icon-linkedin"></i>
            <span></span>
          </a>
        </div>
      </div>

      <!-- <div id="my-desc" class="profile-col profile-col-2 hide">
        <div id="my-desc-title">
          Another me.
        </div>
        <div id="my-desc-content">
          I enjoy running, playing table tennis, movies, music, and so much more<br>
        </div>
      </div> -->
    </div>
  </div>
  <!-- <script type="text/javascript">
    function deepFeature()
    {
      $('#profile-avatar').attr('src', 'images/self-portrait/deep-me.jpg');
      $('#profile-avatar').removeClass('border-dark');
      $('#profile-avatar').addClass('border-bright');

      $('#profile-cover').removeClass('shallow-bg');
      $('#profile-cover').addClass('deep-bg');
      
      $('#profile-namecard').removeClass('wrapper-light');
      $('#profile-namecard').addClass('wrapper-dark');
      
      $('#my-desc').removeClass('hide');
      $('#my-contact').addClass('hide');    
      // console.log('Move in now...');
    }

    function shallowFeature()
    {
      $('#profile-avatar').attr('src', 'images/self-portrait/me.jpg');
      $('#profile-avatar').removeClass('border-bright');
      $('#profile-avatar').addClass('border-dark');

      $('#profile-cover').removeClass('deep-bg');
      $('#profile-cover').addClass('shallow-bg');
      
      $('#profile-namecard').removeClass('wrapper-dark');
      $('#profile-namecard').addClass('wrapper-light');
      
      $('#my-contact').removeClass('hide');
      $('#my-desc').addClass('hide');
      // console.log('Move out now...');
    }

    $(function() { 
      $('#my-pic').hover(deepFeature, shallowFeature);
    })

  </script> -->

<div class="page-content">
<div class="wrapper">
<div id="bio" class="bio">

  <h1 class="md-heading text-left">
    <i class="fa fa-id-card" aria-hidden="true"></i>
    About
  </h1>
  <div class="bio-body" style="overflow:hidden;">
    <p>
		I am a third-year M.S. student at <a href="https://min.sjtu.edu.cn/" target="_blank">Institute of Media, Information, and Network (min), SJTU</a>, 
		advised by <a href="https://min.sjtu.edu.cn/En/FacultyShow/4?Vid=14" target="_blank">Prof. Hongkai Xiong</a> and <a href="https://min.sjtu.edu.cn/En/FacultyShow/4?Vid=20" target="_blank">Prof. Wenrui Dai</a>. 
		During my undergraduate studies, I majored in Electronic Science and Technology and minored in Computer Science at <a href="https://www.sjtu.edu.cn/" target="_blank">SJTU</a>.
      	<br>
		I have a keen interest in machine learning, interpretable AI, and large (language) models. Now I am focusing on reasoning models.
		<br>
		I am currently working with <a href="https://tongzhang-ml.org/" target="_blank">Tong Zhang</a> as a research intern at <a href="https://illinois.edu/" target="_blank">UIUC</a>.
		Previously, I was lucky enough to collaborate with <a href="http://www.yelabs.net/" target="_blank">Jieping Ye</a> @ <a href="https://umich.edu/" target="_blank">UMich</a> 
		and <a href="http://qszhang.com/" target="_blank">Quanshi Zhang</a> @ <a href="https://www.sjtu.edu.cn/" target="_blank">SJTU</a>.
		<br>
		A public up-to-date resume can be found <a href="data/Academic_CV_en.pdf" target="_blank">here</a>. Feel free to contact me!
		
    </p>

    <div style="width: 50%; float:left">
			<h3>
		    <i class="fa fa-star" aria-hidden="true"></i>
		    <strong>Interests</strong>
			</h3>
      <ul>
        <!-- <li><b>Multi-modality</b></li> -->
        <li><b>Machine Learning</b></li><br>
        <!-- <a href="https://arxiv.org/pdf/2506.21539" target="_blank">[WorldVLA]</a><a href="https://arxiv.org/pdf/2503.03464" target="_blank">[Survey]</a><a href="https://arxiv.org/abs/2402.10534" target="_blank">[VLP]</a><a href="https://ieeexplore.ieee.org/abstract/document/9681231" target="_blank">[VPN]</a> -->
        <li><b>Large Language Models</b></li><br>
        <!-- <a href="https://arxiv.org/abs/2403.13261" target="_blank">[STC]</a><a href="https://arxiv.org/abs/2207.01452" target="_blank">[REAL]</a><a href="https://arxiv.org/abs/2108.04562" target="_blank">[DML]</a><a href="https://arxiv.org/abs/2112.01135" target="_blank">[MLUC]</a> -->
        <li><b>Interpretable AI</b></li><br>
        <!-- <a href="https://arxiv.org/abs/2409.08083" target="_blank">[SimMAT]</a><a href="https://arxiv.org/abs/2403.17010" target="_blank">[Calib3D]</a><a href="https://arxiv.org/abs/2305.14207" target="_blank">[Segment Any RGBD]</a><a href="https://arxiv.org/abs/2306.09347" target="_blank">[Segment Any Point Cloud]</a><a href="https://arxiv.org/abs/2405.10305" target="_blank">[PSG-4D]</a><a href="https://arxiv.org/abs/2307.04091" target="_blank">[CMDFusion]</a> -->
        <li><b>Computer Vision</b></li><br>
        <!-- <a href="https://openreview.net/forum?id=xLr0I_xYGAs" target="_blank">[UOSR]</a><a href="https://arxiv.org/abs/2303.15467" target="_blank">[PSL]</a> -->
        <!-- <li><b>Continual Learning</b></li>
        <a href="https://arxiv.org/abs/2403.08568" target="_blank">[CPrompt]</a><a href="https://arxiv.org/abs/2211.00833" target="_blank">[FrameMaker]</a><a href="https://ieeexplore.ieee.org/abstract/document/9665922" target="_blank">[KD-TIL]</a> -->
      </ul>
    </div>

    <div style="width: 50%; float:right">
			<h3>
				<i class="fa fa-graduation-cap" aria-hidden="true"></i>
				<strong>Education</strong>
			</h3>
			<b>Shanghai Jiao Tong University</b><br>
			<ul>
        <li>M.S. in Information and Communication Engineering, Sep. 2023 - Mar. 2026</li>
        <li>Mentor: <a href="https://min.sjtu.edu.cn/En/FacultyShow/4?Vid=14" target="_blank">Prof. Hongkai Xiong</a> and <a href="https://min.sjtu.edu.cn/En/FacultyShow/4?Vid=20" target="_blank">Prof. Wenrui Dai</a> </li>
      </ul>
      <b>Shanghai Jiao Tong University</b><br>
        <ul>
          <li>Major: B.S. in Electronic Science and Technology, Sep. 2019 - June. 2023</li>
          <li>Minor: B.S. in Computer Science and Technology, Sep. 2019 - June. 2023</li>
        </ul>
    </div>
  
  </div>
</div>

<!-- <div id="news" class="bio">
  <h1 class="md-heading text-left">
    <i class="fa fa-tasks" aria-hidden="true"></i>
    News
  </h1>  
  <ul>
    	<li class="indented" data-date="[Feb, 2024]"> Give a talk on <a href="https://arxiv.org/pdf/2402.03675.pdf">protein-protein interaction prediction</a> to <a href="https://jian-tang.com/students/">Jian Tang's group</a>. [<a href="files/ppiretrieval.pdf">Slide</a>]</li>
	<li class="indented" data-date="[Dec, 2023]"> Give a talk on <a href="https://arxiv.org/pdf/2304.14621.pdf">structure-based molecule design</a> at LoG2023 Montreal. [<a href="files/mudiff.pdf">Slide</a>][<a href="https://www.youtube.com/watch?v=Z5l-gaV-DUo">Video</a>]</li>
    	<li class="indented" data-date="[Nov, 2023]"> One paper accepted to 2nd Learning on Graphs Conference.</li>
    	<li class="indented" data-date="[Oct, 2023]"> One paper accepted to 37th Conference on Neural Information Processing Systems.</li>
    	<li class="indented" data-date="[Sep, 2023]"> One paper accepted to 12th International Conference on Complex Networks and their Applications.</li>
   	<li class="indented" data-date="[Oct, 2022]"> One paper accepted to 36th Conference on Neural Information Processing Systems, GLFrontiers, and selected for <b><span style="color: red;">Oral</span></b> presentation.</li>
   	<li class="indented" data-date="[Oct, 2022]"> Two papers accepted to 36th Conference on Neural Information Processing Systems, and one paper selected for <b><span style="color: red;">Spotlight</span></b> presentation.</li>
  </ul>
</div> -->


<div id="publications" class="publications">
  <h1 class="md-heading text-left">
    <i class="fa fa-file" aria-hidden="true"></i>
    Publications (<button class="custom-button" id="show-selected-btn"> Show Representative </button> / <button class="custom-button" id="show-all-btn"> Show All </button>)
  </h1>


  <div class="pub-list">

        <div class="pub" data-selected="true">
          <div class="pub-left">
            <img class="intro-img frame" src="images/salamander.png">
          </div>
          <div class="pub-right">
            <div class="title">
              SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                <b>Yue Xin</b>, Chen Shen, Shaotian Yan, Yaoming Wang, Xiaosong Yuan, Chenxi Huang, Jieping Ye
              </font>
            </div>
            <div class="publish">
              <span class="place">EMNLP 2025</span>
              <span class="place"></span>
            </div>
            <div class="tags">
              [<a class="tag" href="https://arxiv.org/abs/2509.16561" target="_blank">Paper</a>]
            </div>
          </div>
        </div>
	  

	  <div class="pub" data-selected="true">
      <div class="pub-left">
        <img class="intro-img frame" src="images/generation.jpg">
      </div>
      <div class="pub-right">
        <div class="title">
          Generalizable Geometric Image Caption Synthesis
        </div>
        <div class="authors">
          <font style="font-size: 11pt;">
            <b>Yue Xin*</b>, Wenyuan Wang*, Rui Pan*, Ruida Wang, Howard Meng, Renjie Pi, Shizhe Diao, Tong Zhang
          </font>
        </div>
        <div class="publish">
          <span class="place">ICLR 2025 on submission</span>
          <span class="place"></span>
        </div>
        <div class="tags">
          [<a class="tag" href="https://arxiv.org/abs/2509.15217" target="_blank">Paper</a>]
		  [<a class="tag" href="https://machinephoenix.github.io/GeoReasoning_blog/" target="_blank">Blog</a>]
		  [<a class="tag" href="https://huggingface.co/datasets/ScaleMath/GeoReasoning" target="_blank">Dataset</a>]
          [<a class="tag" href="https://github.com/MachinePhoenix/GeoReasoning" target="_blank">Code</a>]
        </div>
      </div>
    </div>
	  

        <div class="pub" data-selected="false">
          <div class="pub-left">
            <img class="intro-img frame" src="images/cfu.png">
          </div>
          <div class="pub-right">
            <div class="title">
               Parameter-Efficient Cross-Layer Feature Fusion via Chebyshev Polynomial Unit
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                <b>Yue Xin</b>, Jiarui Zhang, Ziyang Zheng, Yaoming Wang, Wenrui Dai, Chenglin Li, Junni Zou, Hongkai Xiong
              </font>
            </div>
            <div class="publish">
              <span class="place">VCIP 2025</span>
              <span class="place"></span>
            </div>
            <div class="tags">
              [<a class="tag" href="works/CFU.pdf" target="_blank">Paper</a>]
            </div>
          </div>
        </div>

        <div class="pub" data-selected="false">
          <div class="pub-left">
            <img class="intro-img frame" src="images/gleam.png">
          </div>
          <div class="pub-right">
            <div class="title">
              GLEAM: Global Share Local Transform MoE for Downstream Transferring With Enhanced Parameter Efficiency
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                Jiarui Zhang, <b>Yue Xin</b>, Yaoming Wang, Wenrui Dai, Ziyang Zheng, Chenglin Li, Junni Zou, Hongkai Xiong
              </font>
            </div>
            <div class="publish">
              <span class="place">ECAI 2025</span>
              <span class="place"></span>
            </div>
            <div class="tags">
              [<a class="tag" href="https://ecai2025.org/accepted-papers/#main_track_accepted_papers" target="_blank">Paper</a>]
            </div>
          </div>
        </div>

        <div class="pub" data-selected="false">
          <div class="pub-left">
            <img class="intro-img frame" src="images/adv.png">
          </div>
          <div class="pub-right">
            <div class="title">
              Clarifying the Behavior and the Difficulty of Adversarial Training
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                Xu Cheng*, Hao Zhang*, <b>Yue Xin</b>, Wen Shen, Jie Ren, Quanshi Zhang
              </font>
            </div>
            <div class="publish">
              <span class="place">AAAI 2024</span>
              <span class="place"></span>
            </div>
            <div class="tags">
              [<a class="tag" href="https://ojs.aaai.org/index.php/AAAI/article/view/29032" target="_blank">Paper</a>]
            </div>
          </div>
        </div>

        <div class="pub" data-selected="false">
          <div class="pub-left">
            <img class="intro-img frame" src="images/interact.png">
          </div>
          <div class="pub-right">
            <div class="title">
              Towards the Dynamics of a DNN Learning Symbolic Interactions
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                Qihan Ren, Yang Xu, Junpeng Zhang, <b>Yue Xin</b>, Dongrui Liu, Quanshi Zhang
              </font>
            </div>
            <div class="publish">
              <span class="place">NeurIPS 2024</span>
              <span class="place"></span>
            </div>
            <div class="tags">
              [<a class="tag" href="https://neurips.cc/virtual/2024/poster/94348" target="_blank">Paper</a>]
            </div>
          </div>
        </div>
        
        <div class="pub" data-selected="true">
          <div class="pub-left">
            <img class="intro-img frame" src="images/crft.png">
          </div>
          <div class="pub-right">
            <div class="title">
              Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                Chenxi Huang, Shaotian Yan, Liang Xie, Binbin Lin, Sinan Fan, <b>Yue Xin</b>, Deng Cai, Chen Shen, Jieping Ye
              </font>
            </div>
            <div class="publish">
              <span class="place">ACL 2025</span>
              <span class="place"></span>
            </div>
            <div class="tags">
              [<a class="tag" href="https://aclanthology.org/2025.acl-long.1129/" target="_blank">Paper</a>]
            </div>
          </div>
        </div>
        
        <div class="pub">
          <div class="pub-left">
            <img class="intro-img frame" src="images/rst.png">
          </div>
          <div class="pub-right">
            <div class="title">
                D2-RST: Dual-Dimensional Residual Side Tuning for Mitigating Feature Forgetting in Parameter-Efficient Transfer Learning
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                <b>Yue Xin</b>, Yaoming Wang, Wenrui Dai, Jiarui Zhang, Ziyang Zheng, Chenglin Li, Junni Zou, Hongkai Xiong
              </font>
            </div>
            <div class="publish">
              <span class="place">WACV 2026 on submission</span>
              <span class="place"></span>
            </div>
            <div class="tags">
				[<a class="tag" href="works/D2-RST.pdf" target="_blank">Paper</a>]
            </div>
          </div>
        </div>
        
        <div class="pub">
          <div class="pub-left">
            <img class="intro-img frame" src="images/casunet.png">
          </div>
          <div class="pub-right">
            <div class="title">
              Towards Noise-Robust Medical Segmentation via Chebyshev-Attention-Based Asymmetric UNet
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                <b>Yue Xin</b>, Ziyang Zheng, Wenrui Dai, Chenglin Li, Junni Zou, Hongkai Xiong
              </font>
            </div>
            <div class="publish">
              <span class="place">WACV 2026 on submission</span>
              <span class="place"></span>
            </div>
            <div class="tags">
              [<a class="tag" href="works/CASUNet.pdf" target="_blank">Paper</a>]
            </div>
          </div>
        </div>
        
        <div class="pub" data-selected="true">
          <div class="pub-left">
            <img class="intro-img frame" src="images/">
          </div>
          <div class="pub-right">
            <div class="title">
              A Technical Report on LLM Distillation
            </div>
            <div class="authors">
              <font style="font-size: 11pt;">
                <b>Yue Xin</b>, Shaotian Yan, Kaiyuan Liu, Rui Miao, Bing Wang, Sinan Fan, Chen Shen, Jieping Ye
              </font>
            </div>
            <div class="publish">
              <span class="place">Arxiv 2025</span>
              <span class="place"></span>
            </div>
            <div class="tags">
              <!-- [<a class="tag" href="https://arxiv.org/abs/2307.04091" target="_blank">Paper</a>] -->
            </div>
          </div>
        </div>


        <div class="pub" data-selected="true">
            <div class="pub-left">
              <img class="intro-img frame" src="images/">
            </div>
            <div class="pub-right">
              <div class="title">
                Perplexity-Aware Pruning for Efficient Chain-of-Thought Distillation
              </div>
              <div class="authors">
                <font style="font-size: 11pt;">
                  <b>Yue Xin</b>, Jiaxin Huang
                  <br>
                </font>
              </div>
              <div class="publish">
                <span class="place">ICLR 2026 on submission</span>
                <span class="place"></span>
              </div>
              <div class="tags">
                <!-- [<a class="tag" href="https://arxiv.org/abs/2305.14207" target="_blank">Paper</a>] -->
              </div>
            </div>
          </div>


          <div class="pub" data-selected="true">
            <div class="pub-left">
              <img class="intro-img frame" src="images/pat.png">
            </div>
            <div class="pub-right">
              <div class="title">
                  Bootstrap Prompt Learning with Feature Adaptation for Vision-Language Efficient Tuning
              </div>
              <div class="authors">
                <font style="font-size: 11pt;">
                  Jiarui Zhang, Yaoming Wang, <b>Yue Xin</b>, Wenrui Dai, Ziyang Zheng, Chenglin Li, Junni Zou, Hongkai Xiong
                  <br>
                </font>
              </div>
              <div class="publish">
                <span class="place">ICLR 2026 on submission</span>
                <span class="place"></span>
              </div>
              <div class="tags">
                [<a class="tag" href="works/PAT.pdf" target="_blank">Paper</a>]
              </div>
            </div>
          </div>
        
        
        
        
	    
	      
      </div>
    </div>


	<!-- <div class="wrapper"> -->
  <div id="timeline" class="timeline-brief">
    <h1 class="md-heading text-left">
      <i class="fa fa-tasks" aria-hidden="true"></i>
      Research Experiences
    </h1>
  
    <div class="timeline-body">
      <div class="timeline-item">
        <div class="timeline-org">
            <img class="social-icon" src="images/brand/min.svg"/>
            <a href="https://min.sjtu.edu.cn/" target="_blank">Institute of Media, Information and Network (min), SJTU</a>
        </div>
        <div class="timeline-title">
            Machine Learning and Computer Vision Intern and Master's Student
          </div>
        <div class="timeline-date">
          Nov, 2022 - Present
        </div>
        
        <div class="timeline-desc">
        <div class="timeline-host">
          <b> Advised by <a href="https://min.sjtu.edu.cn/En/FacultyShow/4?Vid=14" target="_blank">Prof. Hongkai Xiong</a> and <a href="https://min.sjtu.edu.cn/En/FacultyShow/4?Vid=20" target="_blank">Prof. Wenrui Dai</a>, my researches include:</b>
            <ul>
                <li>Proposed Chebyshev Fusion Unit (CFU), a lightweight feature fusion method to mitigate the challenge of balancing expressiveness and efficiency. Specifically, CFU computed high-order Chebyshev polynomial terms between residual and current-layer features to explicitly model complex cross-layer dependencies with minimal parameters. Comprehensive experiments verify its strong approximation and optimization capability. (VCIP 2025 accepted) </li>
                <li>Proposed Dual-Dimensional Residual Side Tuning (D2-RST) framework to mitigate feature forgetting and progressive spectral decay in deep layers by employing a dual-block side-tuning structure with low-rank linear mapping on aggregated features, and introducing an additional spatial-dimension pathway in parallel with the feature-dimension pathway. The properties and performance of RST are verified through mathematical proof and various experiments. (WACV 2026 on submission) </li>
                <li>Proposed Chebyshev-Attention-Based Semi-Unet (CASUNet), a noise-resilient framework integrating a Semi-UNet backbone with a novel CPA (Chebyshev Polynomial Aggregation) module by first aggregating hierarchical features then expanding to orthogonal polynomial terms. Theoretical and experimental analysis verify its superior noise immunity and competitive performance. (WACV 2026 on Submission) </li>
                <li>Proposed GLEAM, an efficient fine-tuning method for large model parameters. This method leverages the high similarity of parameter matrices in LoRA to construct a low-rank decomposition, further reducing the number of parameters required for fine-tuning while enhancing performance. (ECAI 2025 accepted) </li>
                <li>Proposed PAT, a fault-tolerant multimodal classifier to solve the problem of conflict between prompter learning and adapter tuning. Specifically, it aligns model representations obtained from Soft Prompt and Adapter-based methods and incorporates contrastive learning loss to enhance model performance and generalization. (ICLR 2026 on submission) </li>
            </ul>
            <!-- Supervisor: <a href="https://prokia.github.io/">Shuangjia Zheng</a> -->
          </div>
        </div>
        </div>
      
  
      
      <div class="timeline-item">
        <div class="timeline-org">
            <img class="social-icon" src="images/brand/washu.svg"/>
            <a href="https://washu.edu/" target="_blank">Hint Lab, WashU</a>
        </div>
        <div class="timeline-title">
            LLM Research Intern
        </div>
        <div class="timeline-date">
          Jun, 2025 - Present
        </div>

        <div class="timeline-desc">
          <div class="timeline-host">
            <b>Advised by <a href="https://teapot123.github.io/" target="_blank">Prof. Jiaxin Huang</a>, my researches include:</b>
            <ul>
            <li>Proposed a perplexity-based method to analyze the long CoT pattern for data selection, after which removed the steps with low perplexity to construct a new dataset. Then conducted SFT and RL on the dataset to enhance the reasoning capacity of LLMs more efficiently without significant degradation of the output diversity. (ICLR 2026 on submission)</li>
            </ul>
          </div>
        </div>
      </div>
  
      
      <div class="timeline-item">
        <div class="timeline-org">
            <img class="social-icon" src="images/brand/uiuc.svg"/>
            <a href="https://illinois.edu/" target="_blank">Tong's Lab, UIUC</a>
        </div>
        <div class="timeline-title">
            MLLM Research Intern
        </div>
        <div class="timeline-date">  
          Mar, 2025 - Aug, 2025
        </div>

        <div class="timeline-desc">
          <div class="timeline-host">
            <b>Advised by <a href="https://tongzhang-ml.org/" target="_blank">Prof. Tong Zhang</a>, my researches include:</b>
            <ul>
            <li>
            Proposed Geo-Image-Textualization, a reinforcement learning-based framework to generate high-quality and geometry-centered multimodal data by utilizing a rule-based data generation pipeline and adopting RAFT to further optimize the captions. Then constructed a dataset named GeoReasoning-10K to bridge the gap between visual and linguistic modalities in the geometry domain. Extensive experiments verify the superiority of the dataset for improving multimodal reasoning capacity. (ICLR 2026 on submission)</li>
            </ul>
          </div>
        </div>
      </div>


      <div class="timeline-item">
        <div class="timeline-org">
            <img class="social-icon" src="images/brand/aliyun.svg"/>
            <a href="https://cn.aliyun.com/" target="_blank">Feitian Lab, Alibaba Cloud</a>
        </div>
        <div class="timeline-title">
            LLM Research Intern
        </div>
        <div class="timeline-date">
          Mar, 2025 - Aug, 2025
        </div>

        <div class="timeline-desc">
          <div class="timeline-host">
            <b>Advised by <a href="http://www.yelabs.net/" target="_blank">Prof. Jieping Ye</a>, my researches include:</b>
            <ul>
            <li>Proposed SalaMAnder, a Shapley-value-based framework for quantifying component-level contributions in CoT reasoning. Specifically, we develop an efficient stratified sampling algorithm to compute Shapley value for mathematical expression attribution and CoSP (Cardinality of Shapley Positives) metric. Theoretical derivation and comprehensive validation across multiple models and benchmarks present a robust monotonic correlation between CoSP and model performance, providing theoretical explanations for the empirical success of CoT. (EMNLP 2025 accepted)
            </li>
            <li>
            Proposed CRFT, a novel method that identifies and optimizes critical representations that integrate significant information from preceding layers or regulate subsequent layer representations. CRFT effectively optimizes the representations in a low-rank linear subspace through information flow analysis. (ACL 2025 accepted)
            </li>
            <li>Explored the mechanism of LLM distillation and explained the pattern of long CoT, after which significantly improved the distilled model's reasoning capacity.
            </li>
            </ul>
          </div>
        </div>
      </div>



      <div class="timeline-item">
        <div class="timeline-org">
            <img class="social-icon" src="images/brand/sjtu.svg"/>
            <a href="https://sjtu-xai-lab.github.io/" target="_blank">Interpretable ML Lab, SJTU</a>
        </div>
        <div class="timeline-title">
            Interpretable Machine Learning Intern
        </div>
        <div class="timeline-date">
          Feb, 2022 - Nov, 2022
        </div>

        <div class="timeline-desc">
          <div class="timeline-host">
            <b>Advised by <a href="http://qszhang.com/" target="_blank">Prof. Quanshi Zhang</a>, my researches include:</b>
            <ul>
            <li>Theoretically derived the analytical solution for multi-step adversarial attacks, which explains the reasons behind the optimization difficulties in adversarial training. This is validated through experimental results. (AAAI 2024 accepted)
            </li>
            <li>Theoretically derived the two-stage dynamic interaction process of DNNs, proving that the network learning process gradually encodes interactions of varying complexity. This provides a theoretical foundation for understanding overfitting. (NeurIPS 2024 accepted)
            </li>
            <li>Theoretically derived and validated the robustness of concepts with different complexities.
            </li>
            </ul>
          </div>
        </div>
      </div>


      <div class="timeline-item">
        <div class="timeline-org">
            <img class="social-icon" src="images/brand/sjtu.svg"/>
            <a href="https://www.sjtu.edu.cn/" target="_blank">SunnyLab, SJTU</a>
        </div>
        <div class="timeline-title">
            Machine Learning and Computer Vision Intern
        </div>
        <div class="timeline-date">
          May, 2021 - May, 2022
        </div>

        <div class="timeline-desc">
          <div class="timeline-host">
            <b>Advised by <a href="https://faculty.sjtu.edu.cn/zhangchongyang/zh_CN/index/177811/list/index.htm" target="_blank">Prof. Chongyang Zhang</a>, my researches include:</b>
            <ul>
            <li>Developed a Swin Transformer-based model to implement instance segmentation of the workpiece welding area.
            </li>
            <li>Designed a space-time filter to remove false positive samples in pedestrian detection. 
            </li>
            <li>Developed a YOLOv5-based model to detect tower cranes, recognize dangerous tower cranes, and label the  electronic fence.
            </li>
            </ul>
          </div>
        </div>
      </div>
  
      
      
  
    <br>
  </div>
  </div>


  <div id="timeline2" class="timeline-brief">
    <h1 class="md-heading text-left">
      <i class="fa fa-tasks" aria-hidden="true"></i>
      Engineering Experiences
    </h1>

    <div class="timeline-body">
        <div class="timeline-item">
          <div class="timeline-org">
              <img class="social-icon" src="images/brand/ql.svg"/>
              <a href="https://www.70capital.com/" target="_blank">Qilin Investment</a>
          </div>
          <div class="timeline-title">
            Quantitative Strategy Research and Machine Learning Intern
            </div>
          <div class="timeline-date">
            Oct, 2024 - Jan, 2025
          </div>
          
          <div class="timeline-desc">
          <div class="timeline-host">
            <b> My research and engineering projects include:</b>
              <ul>
                  <li>Developed various models to complete intraday prediction tasks, surpassing the baseline model in global domains (A-shares) and improving performance in live trading within three weeks. Conducted ablation studies on the model to explain the reasons for performance improvement and validate its generalizability. </li>
                  <li>Fine-tuned the above model to enhance performance by 10% in local domains (ZZ800 and ZZ1000) while maintaining minimal decrease in overall performance. </li>
              </ul>
              <!-- Supervisor: <a href="https://prokia.github.io/">Shuangjia Zheng</a> -->
            </div>
          </div>
          </div>

          </div>
    </div>


    <div id="competitions" class="timeline-brief">
        <h1 class="md-heading text-left">
          <i class="fab fa-trophy"></i>" aria-hidden="true"></i>
          Competitions
        </h1>
    
        <div class="timeline-body">
            <div class="timeline-item">
              <div class="timeline-org">
                  <img class="social-icon" src="images/brand/yan.svg"/>
                  <a href="https://cpipc.acge.org.cn/cw/hp/4" target="_blank">The 20th Chinese Graduate Mathematical Modeling Competition</a>
              </div>
              <div class="timeline-title">
                Nation level, Second Prize
                </div>
              <div class="timeline-date">
                Jan, 2023
              </div>
              </div>
    
              </div>
        </div>

    
</div>
  </div>
</div>
</div>
	
<!-- JavaScript to handle button clicks -->
<script>
  // Get the buttons and publications
  const showSelectedBtn = document.getElementById('show-selected-btn');
  const showAllBtn = document.getElementById('show-all-btn');
  const publications = document.querySelectorAll('.pub');

  // Add event listener to 'Show Selected Publication' button
  showSelectedBtn.addEventListener('click', function() {
    publications.forEach(pub => {
      if (pub.getAttribute('data-selected') === 'true') {
        pub.style.display = 'block';  // Show selected publication
      } else {
        pub.style.display = 'none';  // Hide other publications
      }
    });
  });

  // Add event listener to 'Show All' button
  showAllBtn.addEventListener('click', function() {
    publications.forEach(pub => {
      pub.style.display = 'block';  // Show all publications
    });
  });
</script>

<script>
  const repos = [
    { owner: "alibaba-damo-academy", repo: "WorldVLA", starId: "star-count", forkId: "fork-count" },
    { owner: "GAI4Manipulation", repo: "AwesomeGAIManipulation", starId: "star-count-2", forkId: "fork-count-2" },
    { owner: "Jun-CEN", repo: "CMDFusion", starId: "star-count-3", forkId: "fork-count-3" },
    { owner: "Jun-CEN", repo: "SegmentAnyRGBD", starId: "star-count-4", forkId: "fork-count-4" },
    { owner: "Jun-CEN", repo: "PSL", starId: "star-count-5", forkId: "fork-count-5" },
    { owner: "Jun-CEN", repo: "Unified-Open-Set-Recognition", starId: "star-count-6", forkId: "fork-count-6" },
    { owner: "Jun-CEN", repo: "Open-world-3D-semantic-segmentation", starId: "star-count-7", forkId: "fork-count-7" },
    { owner: "Jun-CEN", repo: "Open-World-Semantic-Segmentation", starId: "star-count-8", forkId: "fork-count-8" },
    { owner: "Jingkang50", repo: "PSG4D", starId: "star-count-9", forkId: "fork-count-9" },
    { owner: "youquanl", repo: "Segment-Any-Point-Cloud", starId: "star-count-10", forkId: "fork-count-10" }
  ];

  async function loadGitHubStats() {
    for (const { owner, repo, starId, forkId } of repos) {
      try {
        const res = await fetch(`https://api.github.com/repos/${owner}/${repo}`);
        if (!res.ok) throw new Error("GitHub API error");
        const data = await res.json();
        document.getElementById(starId).innerText = data.stargazers_count ?? "–";
        document.getElementById(forkId).innerText = data.forks_count ?? "–";
      } catch (e) {
        console.error(`Failed to load stats for ${owner}/${repo}`, e);
        document.getElementById(starId).innerText = "–";
        document.getElementById(forkId).innerText = "–";
      }
    }
  }

  loadGitHubStats();
</script>


<div class="wrapper">
  <div id="awards" class="bio">
    <h1 class="md-heading text-left">
      <i class="fa fa-tasks" aria-hidden="true"></i>
      Selected Honors & Awards
    </h1>
    <ul>
  	<li> <a href="images/RI.jpeg" target="_blank">Outstanding Research Intern, Alibaba Group, 2023.</a> (15 candidates per year)</li>
	<li> Overseas Research Award, HKUST, 2023.</li>
	<li> Postgraduate Studentship, HKUST, 2020-2024.</li>
	<li> School of Engineering Excellent Student Scholarship, HKUST, 2019-2020.</li>
	<li> School of Engineering Entrance Scholarship, HKUST, 2019-2020.</li>
    </ul>
  </div>
</div>

<style>
  .reviewer-section {
    display: flex;
    flex-wrap: wrap;
    margin-top: 8px;
  }

  .reviewer-column {
    flex: 1 1 50%;
    box-sizing: border-box;
    padding-right: 20px;
    font-size: 0.85em; /* 字体略微变小 */
    line-height: 1.6;
    position: relative;
    padding-left: 1em;
    margin-bottom: 4px;
  }

  .reviewer-column::before {
    content: "•";
    position: absolute;
    left: 0;
    color: #555;
  }

  @media (max-width: 600px) {
    .reviewer-column {
      flex: 1 1 100%;
    }
  }

  .reviewer-title {
    margin-top: 12px;
    font-weight: bold;
  }
</style>



<div style="display: flex; justify-content: center; align-items: center;">
  <div style="max-width: 400px; width: 100%;">
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=K9NLvpbM7GH1cTCvhvVlo4LW5p-d2mRZYw6UhrAFw0g&cl=ffffff&w=a"></script>
  </div>
</div>


<footer class="site-footer">
  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>Personal Email:</li>
          <li><a href="mailto:">xinyuexiong [at] sjtu.edu.cn</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
          <a href="https://scholar.google.com/citations?user=AAMp54AAAAAJ&hl=zh-CN" target="_blank" class="icon-button github">
          <i class="ai ai-google-scholar-square icon-github"></i>
            <span></span>
          </a>

          <a href="https://github.com/MachinePhoenix" target="_blank" class="icon-button github">
            <i class="fa fa-github icon-github"></i>
            <span></span>
          </a>

          <!-- <a href="https://www.linkedin.com/in/jun-cen-45b995219/" target="_blank" class="icon-button linkedin">
            <i class="fa fa-linkedin icon-linkedin"></i>
            <span></span>
          </a> -->
         
          <a href="data/Academic_CV_en.pdf" target="_blank" class="icon-button github">
            <i class="ai ai-cv icon-github"></i>
            <span></span>
          </a>
      </div>
	<div class="footer-col footer-col-3">
    	<!--<a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fwillhua127.github.io&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a> -->
	<!-- <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?user=Lxe71v4AAAAJ&hl=en&url=https%3A%2F%2Fscholar.google.com%2Fcitations&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a> -->
		<p class="text">Last updated: Oct, 2025.<br>The style of this website is borrowed from <a href='http://cen-jun.com/' target="_blank">Jun Cen's</a>.</p>
	</div>
  </div>
  </div>

</footer>
    <div class="back-to-top">Top</div>


<script type="text/javascript">
jQuery(document).ready(function() {
    var offset = 220;
    var duration = 500;
    jQuery(window).scroll(function() {
        if (jQuery(this).scrollTop() > offset) {
            jQuery('.back-to-top').fadeIn(duration);
        } else {
            jQuery('.back-to-top').fadeOut(duration);
    
        }
    });
    jQuery('.back-to-top').click(function(event) {
        event.preventDefault();
        jQuery('html, body').animate({scrollTop: 0}, duration);
        return false;
    })
});
</script>
  </body>

<!--
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60071442-1', 'auto');
  ga('send', 'pageview');
</script>
-->

<!--<script src="custom-pub.js"></script>-->
</html>
